{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57a3117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banyak otak manusia yang hancur gara gara coro...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Segeralah beranjak dari negeri ini hai corona,...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pas ada corona byk hal yg jd 'sakitnya ga ngot...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corona kapan selese ak mau nonton konser anjim</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pemerintah plin plan ngasih izin mudik / nggak...</td>\n",
       "      <td>Negatif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Sentimen\n",
       "0  Banyak otak manusia yang hancur gara gara coro...  Negatif\n",
       "1  Segeralah beranjak dari negeri ini hai corona,...  Positif\n",
       "2  pas ada corona byk hal yg jd 'sakitnya ga ngot...  Negatif\n",
       "3     corona kapan selese ak mau nonton konser anjim  Negatif\n",
       "4  pemerintah plin plan ngasih izin mudik / nggak...  Negatif"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Import dataset\n",
    "data=pd.read_excel(\"datasentimen.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7f9389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleansing Result : \n",
      "\n",
      "0    Banyak otak manusia yang hancur gara gara coro...\n",
      "1    Segeralah beranjak dari negeri ini hai corona ...\n",
      "2    pas ada corona byk hal yg jd sakitnya ga ngota...\n",
      "3       corona kapan selese ak mau nonton konser anjim\n",
      "4    pemerintah plin plan ngasih izin mudik nggak i...\n",
      "Name: Tweet, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cleansing\n",
    "import string \n",
    "import re #regex library\n",
    "\n",
    "def remove_tweet_special(text):\n",
    "    # remove non ASCII (emoticon, chinese word, .etc)\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    # remove mention, link, hashtag\n",
    "    text = ' '.join(re.sub(\"([@#x][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).\n",
    "        split())\n",
    "    # remove b',RT, and &amp\n",
    "    text = text.replace(\"b'\",\"\").replace('amp',\"\").replace('RT',\"\")\n",
    "    # remove incomplete URL\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "                \n",
    "data['Tweet'] = data['Tweet'].apply(remove_tweet_special)\n",
    "\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "data['Tweet'] = data['Tweet'].apply(remove_singl_char)\n",
    "\n",
    "#view\n",
    "data['tweet_cleansing'] = data['Tweet'].apply(remove_singl_char)\n",
    "\n",
    "print('Cleansing Result : \\n') \n",
    "print(data['Tweet'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152740dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Folding Result : \n",
      "\n",
      "0    banyak otak manusia yang hancur gara gara coro...\n",
      "1    segeralah beranjak dari negeri ini hai corona ...\n",
      "2    pas ada corona byk hal yg jd sakitnya ga ngota...\n",
      "3       corona kapan selese ak mau nonton konser anjim\n",
      "4    pemerintah plin plan ngasih izin mudik nggak i...\n",
      "Name: tweet_casefolding, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Case Folding --------\n",
    "# gunakan fungsi Series.str.lower() pada Pandas\n",
    "data['tweet_casefolding'] = data['tweet_cleansing'].str.lower()\n",
    "\n",
    "\n",
    "print('Case Folding Result : \\n')\n",
    "print(data['tweet_casefolding'].head())\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56280574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     banyak otak manusia yang hancur gara gara coro...\n",
       "1     segeralah beranjak dari negeri ini hai corona ...\n",
       "2     pas ada corona byk hal yg jd sakitnya gangotak...\n",
       "3       corona kapan selese ak mau nonton konser anjim \n",
       "4     pemerintah plin plan ngasih izin mudik nggakit...\n",
       "                            ...                        \n",
       "75                                       jancok corona \n",
       "76    setidaknya gue bersyukur masih bisa doain lu p...\n",
       "77    april mudahan corona ada obatnya udah seneng b...\n",
       "78            kemarin jualan corona lalu jualan vaksin \n",
       "79    zaman corona emg banyak isis ini susah itu susah \n",
       "Name: tweet_convertnegation, Length: 80, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_negation(text):\n",
    "    text=''.join(i+' ' if i != 'gak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'ga' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'ngga' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'gk' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'nggak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'enggak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tidak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tdk' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tida' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'tak' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bukan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bkan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'bkn' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'jangan' else i for i in text.split())\n",
    "    text=''.join(i+' ' if i != 'jgn' else i for i in text.split())\n",
    "    return ''.join(i+' ' if i != 'kurang' else i for i in text.split())\n",
    "              \n",
    "data['tweet_convertnegation'] = data['tweet_casefolding'].apply(convert_negation)\n",
    "data['tweet_convertnegation'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff73e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [banyak, otak, manusia, yang, hancur, gara, ga...\n",
      "1     [segeralah, beranjak, dari, negeri, ini, hai, ...\n",
      "2     [pas, ada, corona, byk, hal, yg, jd, sakitnya,...\n",
      "3     [corona, kapan, selese, ak, mau, nonton, konse...\n",
      "4     [pemerintah, plin, plan, ngasih, izin, mudik, ...\n",
      "                            ...                        \n",
      "75                                     [jancok, corona]\n",
      "76    [setidaknya, gue, bersyukur, masih, bisa, doai...\n",
      "77    [april, mudahan, corona, ada, obatnya, udah, s...\n",
      "78      [kemarin, jualan, corona, lalu, jualan, vaksin]\n",
      "79    [zaman, corona, emg, banyak, isis, ini, susah,...\n",
      "Name: tweet_tokens, Length: 80, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------ Tokenizing ---------\n",
    "# import word_tokenize from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "def tokenizing(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "data['tweet_tokens'] = data['tweet_convertnegation'].apply(tokenizing)\n",
    "\n",
    "print(data['tweet_tokens'].head(80))\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3e1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [banyak, otak, manusia, yang, hancur, gara, ga...\n",
       "1     [segeralah, beranjak, dari, negeri, ini, hai, ...\n",
       "2     [pas, ada, corona, banyak, hal, yang, jadi, sa...\n",
       "3     [corona, kapan, selese, aku, mau, menonton, ko...\n",
       "4     [pemerintah, plin, plan, kasih, izin, mudik, n...\n",
       "                            ...                        \n",
       "75                                     [jancok, corona]\n",
       "76    [setidaknya, saya, bersyukur, masih, bisa, doa...\n",
       "77    [april, mudahan, corona, ada, obatnya, sudah, ...\n",
       "78      [kemarin, jualan, corona, lalu, jualan, vaksin]\n",
       "79    [zaman, corona, memang, banyak, isis, ini, sus...\n",
       "Name: tweet_normalization, Length: 80, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalization_word = pd.read_excel(\"normalization.xlsx\")\n",
    "\n",
    "normalization_word_dict = {}\n",
    "\n",
    "for index, row in normalization_word.iterrows():\n",
    "    if row[0] not in normalization_word_dict:\n",
    "        normalization_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalization_term(document):\n",
    "    return [normalization_word_dict[term] if term in normalization_word_dict else term for term in document]\n",
    "\n",
    "data['tweet_normalization'] = data['tweet_tokens'].apply(normalization_term)\n",
    "\n",
    "data['tweet_normalization'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f80e65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [otak, manusia, hancur, gara, gara, corona, ku...\n",
       "1     [segeralah, beranjak, negeri, hai, corona, pen...\n",
       "2                  [pas, corona, sakitnya, gangotakhem]\n",
       "3             [corona, selese, menonton, konser, anjim]\n",
       "4     [pemerintah, plin, plan, kasih, izin, mudik, n...\n",
       "                            ...                        \n",
       "75                                     [jancok, corona]\n",
       "76    [bersyukur, doakan, pas, sedih, terjangkit, co...\n",
       "77    [april, mudahan, corona, obatnya, senang, bang...\n",
       "78            [kemarin, jualan, corona, jualan, vaksin]\n",
       "79                  [zaman, corona, isis, susah, susah]\n",
       "Name: tweet_stopwordremoval, Length: 80, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "stopwords_txt = open(\"stopword_id.txt\", \"r\")\n",
    "\n",
    "\n",
    "stopword_dict = []\n",
    "for word in stopwords_txt:\n",
    "    stopword_dict.append(word.rstrip())\n",
    "list_stopword=stopword_factory.get_stop_words()+stopword_dict\n",
    "\n",
    "def remove_stopword(words):\n",
    "    return [word for word in words if word not in list_stopword]\n",
    "\n",
    "data['tweet_stopwordremoval']= data['tweet_normalization'].apply(remove_stopword)\n",
    "data['tweet_stopwordremoval'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f63399d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [otak, manusia, hancur, gara, gara, corona, ku...\n",
       "1     [segera, anjak, negeri, hai, corona, didik, be...\n",
       "2                     [pas, corona, sakit, gangotakhem]\n",
       "3               [corona, selese, tonton, konser, anjim]\n",
       "4     [perintah, plin, plan, kasih, izin, mudik, ngg...\n",
       "                            ...                        \n",
       "75                                     [jancok, corona]\n",
       "76           [syukur, doa, pas, sedih, jangkit, corona]\n",
       "77    [april, mudah, corona, obat, senang, banget, sih]\n",
       "78                [kemarin, jual, corona, jual, vaksin]\n",
       "79                  [zaman, corona, isis, susah, susah]\n",
       "Name: tweet_stemming, Length: 80, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def Stem(remove_stopword): \n",
    "    return [stemmer.stem(word) for word in remove_stopword]\n",
    "\n",
    "data['tweet_stemming']= data['tweet_stopwordremoval'].apply(Stem)\n",
    "data['tweet_stemming'].head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa0fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"Preprocessing.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdead358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
